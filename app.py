import streamlit as st
import pdfplumber
from PIL import Image
import pytesseract
import cv2
import numpy as np
import re
import requests
from deep_translator import GoogleTranslator

# ---------------- CONFIG ----------------
JSON_URL = "https://raw.githubusercontent.com/oozh15/app/main/tamil.json"

st.set_page_config(
    page_title="Tamil Lexicon Pro",
    layout="wide"
)

# ---------------- DATASET ----------------
@st.cache_data(ttl=3600)
def load_dataset():
    try:
        r = requests.get(JSON_URL, timeout=10)
        if r.status_code == 200:
            return r.json()   # must be dict format
    except:
        pass
    return {}

# ---------------- NORMALIZATION ----------------
def normalize_tamil(word):
    suffixes = [
        "роХро│рпН","ро╡ро┐ро▓рпН","роЗро▓рпН","роЖро▓рпН","роХрпНроХрпБ","роЙроорпН",
        "роР","роЖроХ","роЗройрпН","роЙроЯройрпН","рокро╛ро▓рпН"
    ]
    for s in suffixes:
        if word.endswith(s):
            return word[:-len(s)]
    return word

# ---------------- WIKTIONARY ----------------
def wiktionary_lookup(word):
    try:
        url = f"https://ta.wiktionary.org/wiki/{word}"
        html = requests.get(url, timeout=10).text
        match = re.search(r"<ol>.*?<li>(.*?)</li>", html, re.S)
        if match:
            clean = re.sub("<.*?>", "", match.group(1))
            return clean.strip()
    except:
        pass
    return None

# ---------------- MEANING ENGINE ----------------
def get_precision_meaning(word_tam):
    word_tam = normalize_tamil(word_tam.strip())

    dataset = load_dataset()

    # TIER 1 тАФ DATASET (HIGHEST ACCURACY)
    if word_tam in dataset:
        entry = dataset[word_tam]
        meaning = entry.get("meaning", "тАФ")
        antonyms = ", ".join(entry.get("antonym", [])) or "роХро┐роЯрпИроХрпНроХро╡ро┐ро▓рпНро▓рпИ"

        return (
            f"'{word_tam}' роОройрпНрокродройрпН родрпБро▓рпНро▓ро┐ропрооро╛рой рокрпКро░рпБро│рпН '{meaning}' роЖроХрпБроорпН. "
            f"роЗродройрпН роОродро┐ро░рпНроЪрпНроЪрпКро▓рпН(роХро│рпН): {antonyms}.",
            "Tamil Dictionary Dataset"
        )

    # TIER 2 тАФ WIKTIONARY
    wiki = wiktionary_lookup(word_tam)
    if wiki:
        return (
            f"'{word_tam}' роОройрпНрокродройрпН рокрпКро░рпБро│рпН '{wiki}' роЖроХрпБроорпН. "
            f"роОродро┐ро░рпНроЪрпНроЪрпКро▓рпН родроХро╡ро▓рпН роЗро▓рпНро▓рпИ.",
            "Tamil Wiktionary"
        )

    # TIER 3 тАФ TRANSLATION (LAST RESORT)
    try:
        en = GoogleTranslator(source="ta", target="en").translate(word_tam)
        ta = GoogleTranslator(source="en", target="ta").translate(en)

        return (
            f"'{word_tam}' роОройрпНрокродройрпН рокрпКродрпБро╡ро╛рой рокрпКро░рпБро│рпН '{ta}' роЖроХрпБроорпН. "
            f"роЗродрпБ роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓ро╛рой ро╡ро┐ро│роХрпНроХроорпН.",
            "Translator (Fallback)"
        )
    except:
        return (
            "рооройрпНройро┐роХрпНроХро╡рпБроорпН, роЗроирпНродроЪрпН роЪрпКро▓рпНро▓ро┐ро▒рпНроХро╛рой рокрпКро░рпБро│рпН роХро┐роЯрпИроХрпНроХро╡ро┐ро▓рпНро▓рпИ.",
            "Not Found"
        )

# ---------------- OCR ENGINE ----------------
def ocr_engine(img):
    img = np.array(img)
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    _, thresh = cv2.threshold(
        gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
    )
    config = r"--oem 3 --psm 4 -l tam"
    return pytesseract.image_to_string(thresh, config=config).strip()

# ---------------- UI STATE ----------------
if "history" not in st.session_state:
    st.session_state.history = []

col1, col2 = st.columns([1, 1])

# ---------------- LEFT PANEL ----------------
with col1:
    st.subheader("ЁЯУД роЖро╡рогрокрпН рокродро┐ро╡рпЗро▒рпНро▒роорпН")
    file = st.file_uploader(
        "PDF / Image рокродро┐ро╡рпЗро▒рпНро▒рпБроХ",
        type=["pdf", "png", "jpg", "jpeg"]
    )

    if file:
        with st.spinner("родрооро┐ро┤рпН роЙро░рпИ рокро┐ро░ро┐родрпНродрпЖроЯрпБроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ..."):
            text = ""
            if file.type == "application/pdf":
                with pdfplumber.open(file) as pdf:
                    for page in pdf.pages:
                        text += ocr_engine(
                            page.to_image(resolution=500).original
                        ) + "\n\n"
            else:
                text = ocr_engine(Image.open(file))

            st.text_area("Extracted Tamil Text", text, height=450)

# ---------------- RIGHT PANEL ----------------
with col2:
    st.subheader("ЁЯФН роЪрпКро▓рпН родрпЗроЯро▓рпН")

    with st.form("search_form", clear_on_submit=True):
        word = st.text_input("родрпЗроЯ ро╡рпЗрогрпНроЯро┐роп роЪрпКро▓рпН")
        submit = st.form_submit_button("родрпЗроЯрпБроХ")

        if submit and word:
            meaning, src = get_precision_meaning(word)
            st.session_state.history.insert(
                0, {"word": word, "exp": meaning, "src": src}
            )

    for item in st.session_state.history:
        with st.expander(f"ЁЯУЦ {item['word']} ({item['src']})", expanded=True):
            st.write(item["exp"])

# ---------------- SIDEBAR ----------------
if st.sidebar.button("ЁЯз╣ Clear History"):
    st.session_state.history = []
    st.rerun()
