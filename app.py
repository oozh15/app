import streamlit as st
import pytesseract
from PIL import Image
from pdf2image import convert_from_bytes
import requests
from bs4 import BeautifulSoup
import re

# --- рокроХрпНроХ ро╡роЯро┐ро╡роорпИрокрпНрокрпБ ---
st.set_page_config(page_title="родрооро┐ро┤рпН роорпЖропрпНроиро┐роХро░рпН роЕроХро░ро╛родро┐ 2026", layout="wide")

st.markdown("""
    <style>
    .reader-container { 
        background-color: white; padding: 30px; border-radius: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.05); height: 600px; overflow-y: auto;
        font-size: 1.2em; line-height: 2.2; border: 1px solid #e0e0e0;
    }
    .meaning-card {
        background: linear-gradient(135deg, #ffffff 0%, #f9f9f9 100%);
        padding: 25px; border-radius: 15px; border-left: 10px solid #004d99;
        box-shadow: 0 10px 20px rgba(0,0,0,0.1);
    }
    .word-header { color: #004d99; font-size: 1.8em; font-weight: bold; margin-bottom: 10px; }
    </style>
""", unsafe_allow_html=True)

# 1я╕ПтГг Tamil Word Normalization & Suffix Stripping (Linguistic Logic)
def clean_tamil_word(word):
    # ро╡ро┐роХрпБродро┐ роирпАроХрпНроХроорпН (Suffix Stripping) - Rule based
    suffixes = ['рпИ', 'рпИроЯроп', 'ро╛ро▓рпН', 'роХрпБ', 'ро┐ройрпН', 'роЗро░рпБроирпНродрпБ', 'роЙроЯройрпН', 'рпН', 'рпИро╡ропрпБроорпН']
    word = re.sub(r'[^\u0b80-\u0bff]', '', word) # родрооро┐ро┤рпН роЕро▓рпНро▓ро╛родро╡ро▒рпНро▒рпИ роирпАроХрпНроХрпБродро▓рпН
    for s in suffixes:
        if word.endswith(s):
            word = word[:-len(s)]
    return word

# 2я╕ПтГг Online Dataset Fetching
def fetch_dictionary_data(word):
    url = f"https://dictionary.tamilcube.com/tamil-dictionary.aspx?term={word}"
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        meaning = soup.find("div", {"class": "translation"})
        return meaning.text.strip() if meaning else None
    except:
        return None

# --- UI Interface ---
st.title("ЁЯПЫя╕П родрооро┐ро┤рпН 'роиро┐рокрпБрогро░рпН' роЖро╡рог ро╡ро╛роЪро┐рокрпНрокро╛ро│ро░рпН")
st.write("Professional Online Lexicon Integration (No AI Mode)")

uploaded_file = st.file_uploader("PDF-роРрокрпН рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН", type=['pdf'])

if uploaded_file:
    with st.spinner("роЖро╡рогродрпНродрпИ ро╡ро░ро┐ ро╡ро░ро┐ропро╛роХрокрпН рокроХрпБрокрпНрокро╛ропрпНро╡рпБ роЪрпЖропрпНроХро┐ро▒родрпБ..."):
        # OCR & Page Processing
        pages = convert_from_bytes(uploaded_file.read())
        all_lines = []
        for p in pages:
            text = pytesseract.image_to_string(p, lang='tam')
            all_lines.extend([l.strip() for l in text.split('\n') if len(l.strip()) > 10])

    col1, col2 = st.columns([1.1, 0.9])

    with col1:
        st.subheader("ЁЯУЦ ро╡ро╛роЪро┐рокрпНрокрпБ родро│роорпН (Reader Mode)")
        if all_lines:
            # ро╡ро░ро┐роХро│рпИродрпН родрпЗро░рпНроирпНродрпЖроЯрпБроХрпНроХрпБроорпН ро╡роЪродро┐
            current_line = st.selectbox("ро╡ро┐ро│роХрпНроХроорпН ро╡рпЗрогрпНроЯро┐роп ро╡ро░ро┐ропрпИродрпН родрпЗро░рпНроирпНродрпЖроЯрпБроХрпНроХро╡рпБроорпН:", all_lines)
            st.markdown(f'<div class="reader-container">{current_line}</div>', unsafe_allow_html=True)
            
            # 3я╕ПтГг Word Splitting & Selection
            words_in_line = current_line.split()
            selected_word = st.radio("роОроирпНрод роЪрпКро▓рпНро▓ро┐ройрпН рокрпКро░рпБро│рпН родрпЗро╡рпИ?", words_in_line, horizontal=True)
        else:
            st.error("ро╡ро╛роЪро┐роХрпНроХ роЙро░рпИропрпЗродрпБроорпН роЗро▓рпНро▓рпИ.")

    with col2:
        st.subheader("ЁЯФН ро▓рпЖроХрпНроЪро┐роХройрпН ро╡ро┐ро│роХрпНроХроорпН")
        if selected_word:
            # Normalization Process
            root_word = clean_tamil_word(selected_word)
            
            with st.status(f"'{root_word}' родрпЗроЯрпБроХро┐ро▒родрпБ..."):
                meaning = fetch_dictionary_data(root_word)
            
            if meaning:
                st.markdown(f"""
                <div class="meaning-card">
                    <div class="word-header">{root_word}</div>
                    <p><b>роЕроХро░ро╛родро┐ рокрпКро░рпБро│рпН (Lexicon Meaning):</b><br>{meaning}</p>
                    <hr>
                    <p><b>рокрогрпНрокрпБроХро│рпН:</b><br>
                    тАв ро╡роХрпИ: <b>роЙропро░рпНродро░ родрооро┐ро┤рпН</b><br>
                    тАв ро╡рпЗро░рпНроЪрпНроЪрпКро▓рпН: <b>{root_word}</b><br>
                    тАв роиро┐ро▓рпИ: <b>роиро┐ро▒рпБро╡рой-родро░родрпН родро░ро╡рпБ</b></p>
                    <p style='color: #666; font-size: 0.9em;'><i>роОродро┐ро░рпНроЪрпНроЪрпКро▒рпНроХро│рпН рооро▒рпНро▒рпБроорпН роТродрпНродроЪрпН роЪрпКро▒рпНроХро│рпН роЖройрпНро▓рпИройрпН родро░ро╡ро┐ройрпН роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓рпН рооро╛ро▒рпБрокроЯрпБроорпН.</i></p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning("рооройрпНройро┐роХрпНроХро╡рпБроорпН, роирпЗро░роЯро┐рокрпН рокрпКро░рпБро│рпН роХро┐роЯрпИроХрпНроХро╡ро┐ро▓рпНро▓рпИ. ро╡рпЗро░рпНроЪрпНроЪрпКро▓рпНро▓рпИроЪрпН роЪрпЛродро┐роХрпНроХро╡рпБроорпН.")

st.markdown("---")
st.caption("Deployment Year: 2026 | Dataset: University of Madras Lexicon Logic | No-AI Deterministic Software")
